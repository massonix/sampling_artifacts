---
title: "SmartSeq2 validation"
author: "Ramon Massoni-Badosa"
date: "11/14/2018"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = "100%", fig.align='center', 
                      message=FALSE, warning = FALSE)
options(width = 1200)
```


# Introduction
Up until now, we have seen that time at room temperature before cryopreservation introduces technical artifacts in the transcriptome of PBMCs. We also found cell type-specific meta-signatures that can predict and correct time-affected cells. In this notebook, we seek to elucidate whether these findings are robust in other technologies. Particularly, we used [Smart-seq2](https://www.nature.com/articles/nprot.2014.006) to profile the transcriptomes of ~384 cells (4 96-well plates) coming from the same two donors (male and female).

# Quality Control

## Pre-processing

### Package loading

```{r}
library(SingleCellExperiment)
library(scater)
library(scran)
library(Seurat, lib.loc = "lib")
# library(EnsDb.Hsapiens.v86)
library(ggpubr)
library(org.Hs.eg.db)
library(biomaRt)
library(SC3)
library(pheatmap)
# library(MAST)
library(BiocStyle)
library(purrr)
library(kBET)
library(ggrepel)
library(cluster)
library(tidyverse)
```

### Source function definitions

```{r}
source("bin/utils.R")
```

### Data import
Let us start by importing the raw tables of counts and the cell metadata:

```{r}
date <- Sys.Date()

# Import data
plates <- c("P2568", "P2664", "P2671", "P2672")
counts_l <- map(plates, function(x) {
  counts_file <- str_c("data/JULIA_01/counts/", x, ".tsv.gz")
  read_tsv(gzfile(counts_file), col_names = TRUE)
})
names(counts_l) <- plates

# Create expression matrix: rows are genes(ensembl ids) and columns are cells
# each entry represents the expression level of a particular gene in a given 
# cell
counts_l_mat <- map(counts_l, function(df) {
  mat <- as.matrix(df[, 2:ncol(df)])
  rownames(mat) <- df[[1]]
  mat
})

# Join 4 matrices into 1
counts_mat <- Reduce(cbind, counts_l_mat)

# Load cell metadata 
cell_meta <- read.delim(
  "data/JULIA_01/indexes.tsv", 
  header = TRUE, 
  stringsAsFactors = FALSE, 
  row.names = 1
)
head(cell_meta)
```

We can recode the sample variable of the cell metadata to find the plate, time, sex and marker.

```{r}
cell_meta <- cell_meta %>% 
  mutate(sample = str_replace(sample, "_RT", "")) %>% 
  mutate(sample = str_replace(sample, "_4C", "4C")) %>% 
  separate(sample, c("plate", "time", "donor", "marker")) %>% 
  dplyr::select(- "marker") %>% 
  mutate(donor = ifelse(donor == "M", "male", "female"),
         plate = str_extract(rownames(cell_meta), "P...."))
head(cell_meta)
```


### Create SingleCellExperiment object
In our scRNA-seq analysis, we will store our data in a `SingleCellExperiment` object. This object is a container specialized to work with scRNA-seq data, as it lets us store in a single object the expression matrix, the cell metadata, the gene metadata, the spike-ins and dimensionality reduction parameters, among others. Furthermore, it has special getter/setter methods that make it easy to access and subset the data.

We start by creating the `SingleCellExperiment` object, in which we use the following data:

1. Expression matrix: stored in the counts_mat variable, with rownames corresponding to ensembl gene ids and colnames corresponding to the cell identifier.
2. Cell metadata: stored in the cell_meta variable, which is a dataframe that has 4 variables: plate (plate id), time, donor (male/female), and well. The rownames are the cell identifiers.
3. Gene metadata: ensembl gene ids, stored in the rownames of counts_mat.
4. Mitochondrial genes: used as a control to identify poor-quality cells, obtained from [this tutorial]https://hemberg-lab.github.io/scRNA.seq.course/cleaning-the-expression-matrix.html

```{r}
# Create SingleCellExperiment object
sce <- SingleCellExperiment(
  assays = list(counts = counts_mat),
  rowData = data.frame(ensembl_id = rownames(counts_mat)),
  colData = cell_meta
)
sce

# Remove genes not expressed in any cell
keep_feature <- rowSums(counts(sce)) > 0
sce <- sce[keep_feature, ]

# Define control features (mitochondrial genes)
mt_genes <- c("ENSG00000198899", "ENSG00000198727", "ENSG00000198888",
              "ENSG00000198886", "ENSG00000212907", "ENSG00000198786",
              "ENSG00000198695", "ENSG00000198712", "ENSG00000198804",
              "ENSG00000198763", "ENSG00000228253", "ENSG00000198938",
              "ENSG00000198840")
isSpike(sce, "MT") <- str_sub(rownames(sce), 1, 15) %in% mt_genes
```

## Cell QC

### Calculate QC metrics

To calculate the cell quality control metrics, we will use the `calculateQCMetrics` function from the `scater` package, which computes a series of QC metrics for each cell (such as library size and number of detected genes), and stores them as new variables in the column metadata of the `SingleCellExperiment` object.

```{r}
sce <- calculateQCMetrics(
  sce,
  feature_controls = list(MT = isSpike(sce, "MT"))
)
head(colnames(colData(sce)), 10)
```

### Library size

We first filter out cells that have a too small library (total number of RNA molecules) in comparison with other cells. Such cells are likely to have broken or failed to capture. Moreover, we will also filter cells with too many reads, as they are likely doublets:

```{r}
lib_size_qc <- as.data.frame(colData(sce)) %>% 
  mutate(discard = ifelse(total_counts < 75000 | total_counts > 1000000, TRUE, FALSE)) %>% 
  ggplot(aes(total_counts, fill = discard)) + 
    geom_histogram(bins = 100, col = "black", alpha = 0.8) +
    geom_vline(xintercept = 75000, color = "red", linetype = "dashed") +
    geom_vline(xintercept = 1000000, color = "red", linetype = "dashed") +
    scale_x_continuous("Library Size") +
    scale_y_continuous(expand = c(0,0)) + 
    scale_fill_manual(values = c("darkgrey", "red")) +
    ggtitle("JULIA_01 - Library Size") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
lib_size_qc
```

Consistent with the distribution, we will exclude cells with fewer than 75,000 total counts. As we can see, this is a data-driven filter, as the threshold is established from the comparison between library sizes. Notably, we see how there are a few cells that have library sizes close to 0, which are likely to be the results of empty wells. Furthermore, we exclude cells with a library size greater than 1,000,000 counts, as they are likely doublets:

```{r}
table(sce$total_counts > 75000 & sce$total_counts < 1000000)
keep_lib_size <- sce$total_counts > 75000 & sce$total_counts < 1000000
```

### Cell coverage

Another filter is the cell coverage, which is the number of expressed genes in each cell (i.e., number of genes with non-zero counts for a given cell). We want to ensure that the reads are distributed across the transcriptome. Thus, we rule out those cells that have an abnormally low number of detected genes.

```{r}
cell_coverage_hist <- as.data.frame(colData(sce)) %>% 
  mutate(discard = ifelse(total_features_by_counts < 435 | total_features_by_counts > 1500, TRUE, FALSE)) %>% 
  ggplot(aes(total_features_by_counts, fill = discard)) + 
    geom_histogram(bins = 100, col = "black", alpha = 0.8) +
    geom_vline(xintercept = 435, color = "red", linetype = "dashed") +
    scale_x_continuous("number of detected genes") +
    scale_y_continuous(expand = c(0,0)) +
    scale_fill_manual(values = c("darkgrey", "red")) +
    ggtitle("JULIA_01 - Cell Coverage") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5), legend.position = "none") 

library_quality <- ifelse(
  sce$total_features_by_counts > 435 & sce$total_features_by_counts < 1500, 
  "good", 
  "bad"
)
sce$`Library Quality` <- library_quality
cumul_dis <- plotScater(
  sce, 
  nfeatures = 300, 
  colour_by = "Library Quality", 
  exprs_values = "counts"
)
cell_coverage_qc <- ggarrange(
  plotlist = list(cell_coverage_hist, cumul_dis), 
  nrow = 1, 
  ncol = 2
)
cell_coverage_qc
```

We see that the vast majority of cells have a cell coverage >435 and lower than 1500, so we rule out cells with less or more detected genes, respectively:

```{r}
table(sce$total_features_by_counts > 435  & sce$total_features_by_counts < 1500)
keep_cell_cover <- sce$total_features_by_counts > 435 & sce$total_features_by_counts < 1500
```


### Mitochondrial genes

The third cell filter we aim to apply is based on the percentage of counts for mitochondrial genes. It is expected that poor-quality cells are enriched for the expression of mitochondrial genes, likely because cells undergo apoptosis:

```{r}
mt_genes_qc <- as.data.frame(colData(sce)) %>% 
  mutate(discard = ifelse(pct_counts_MT > 20, TRUE, FALSE)) %>% 
  ggplot(aes(pct_counts_MT, fill = discard)) +
    geom_histogram(bins = 100, col = "black", alpha = 0.8) +
    geom_vline(xintercept = 20, colour = "red", linetype = "dashed") +
    scale_x_continuous("Mitochondrial proportion (%)") +
    scale_y_continuous(expand = c(0, 0)) +
    scale_fill_manual(values = c("darkgrey", "red")) +
    ggtitle("JULIA_01 - Mitochondrial gene expression") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5), legend.position = "none")  

mt_genes_qc
```

Again, we will exclude cells with a data-driven filter, in this case those having a percentage of mitochondrial counts greater than 20.

```{r}
table(sce$pct_counts_MT < 20)
keep_low_mt_pct <- sce$pct_counts_MT < 20
```

### Exploratory analysis of and filtering of poor-quality cells
After establishing the threshold for 3 QC metrics: library size, cell coverage and % of mitochondrial genes, we proceed to filter out those cells that are an outlier in any of this metrics. Note that, although there are cells that are outliers in all 3 metrics, we only require a cell to be an outlier in a single metric to be considered as low-quality.

First, however, let us run and plot a tSNE to ensure the cells we discarded are indeed outliers due to technical reasons:

```{r}
use_cells <- keep_lib_size & keep_cell_cover & keep_low_mt_pct
table(use_cells)
sce$lib_quality <- use_cells
cell_quality_tsne <- plot_tsne(
  sce, 
  exprs_values = "counts", 
  color_by = "lib_quality", 
  point_size = 2.5, 
  point_alpha = 1,
  colors = c("red2", "seagreen3"),
  title = "Poor-quality cells",
  subtitle = "<75,000 counts, <435 detected genes, >20% mitochondrial expression"
)
cell_quality_tsne

# Save QC plots into a single figure
qc_plots <- ggarrange(
  plotlist = list(lib_size_qc, cell_coverage_hist, mt_genes_qc, cumul_dis, cell_quality_tsne),
  ncol = 3, 
  nrow = 2,
  common.legend = TRUE
)
qc_plots
```

Moreover, we can explore whether poor-quality cells correlate with time until freezing. That is, we expect that the greater the time that goes by before a sample is frozen, the larger the number of poor-quality cells in that sample:

```{r}
# Compute the % of poor-quality cells per time-point
time_order_all <- c("0h", "2h", "8h", "24h", "24hbiobank", "48h", "24h4C", "48h4C")
poor_quality_df <- as.data.frame(colData(sce)) %>% 
  dplyr::filter(time != "empty" & !is.na(time)) %>% 
  dplyr::select("time", "lib_quality") %>% 
  group_by(time) %>% 
  summarize(n_cells = n(),
            pct_poor_quality = sum(!lib_quality) / n_cells * 100) %>% 
  mutate(time = factor(time, rev(time_order_all)))

# Plot the % of poor-quality cells per time-point
poor_quality_gg <- poor_quality_df %>% 
  ggplot(aes(time, pct_poor_quality)) +
      geom_col() +
      scale_y_continuous("Proportion poor-quality cells (%)", expand = c(0, 0),
                         limits = c(0, 40)) +
      scale_x_discrete(name = "") +
      theme_bw() +
      theme(panel.grid.major.y = element_blank(),
            axis.title = element_text(size = 11, face = "bold"),
            axis.text.y = element_text(size = 10)) +
      coord_flip()

# Save plot
ggsave(
  filename = str_c("results/plots/", date, "_SmartSeq2_low_quality_by_time.pdf"), 
  plot = poor_quality_gg,
  device = "pdf",
  width = 9
)
poor_quality_gg
```

Our data suggests that 48h at 4ºC decreases cell viability, which is consistent with [other studies](https://translational-medicine.biomedcentral.com/articles/10.1186/1479-5876-9-26).

Finally, we can proceed to filter the low-quality cells:

```{r}
sce <- sce[, use_cells]
```

We discarded 68 cells and kept the remaining 316. However, we observe the following problem:

```{r}
colData(sce)[sce$time == "empty" & !is.na(sce$time == "empty"), 
             c("time","plate", "well", "total_counts")]
```

We see that there are 4 cells that were annotated as "empty", but they contain > 231698 total counts each.

The plate distributions were the following:

```{r fig.height=7, fig.width=14}
plate_distrs <- map(plates, function(x){
  curr_sce <- sce[, sce$plate == x]
  plate_distr <- plotPlatePosition(
    curr_sce, 
    plate_position = curr_sce$well, 
    colour_by = "time")
  plate_distr + ggtitle(x)
})
plate_distrs
plate_distrs <- ggarrange(plotlist = plate_distrs, nrow = 2, ncol = 2)
ggsave(
  filename = str_c("results/plots/", date, "Smart-seq2_plate_distr.pdf"), 
  plot = plate_distrs,
  device = "pdf", 
  height = 18,
  width = 22
)
```

**Remark** We contacted the people in the wet-lab and they reported that the technician who performed the FACS sorting misanotated the wells as "empty", but they indeed had a cell. Mail titled "JULIA_SmartSeq plates", received 15 feb. 2019 16:20.

## Gene QC

### Gene filtering
Gene filtering must be performed right after cell filtering, as some genes may be exlusively expressed in poor-quality cells. The purpose of this step is to remove lowly expressed genes that do not possess enough information for reliable statistical analysis. Furthermore, the discreteness of the counts can affect the reliability of downstream analysis. This genes contain a great deal of dropout events: transcripts that are not detected in the final dataset even though the gene is expressed in the cell.

To filter low-abundance genes we have two options:

1. Filter out genes with a mean expression across cells below a given cutoff
2. Filter out genes with fewer than a given number of cells meeting a minimum cutoff.

We prefer the first option as it is less agressive. Moreover, in order for a gene to be retained it needs to have a sufficient expression in a subset of cells. 

We can check the accuracy of the cutoff graphically. We start by calculating the mean gene expression across cells and visualizing its log-distribution. A reasonable threshold is an average count of 1:

```{r}
mean_expr <- log10(rowMeans(counts(sce)) + 0.25)
gene_expr_distr <- as.data.frame(mean_expr) %>%
  mutate(discard = ifelse(mean_expr < 0, TRUE, FALSE)) %>% 
  ggplot(aes(mean_expr, fill = discard)) + 
    geom_histogram(bins = 100, col = "black", alpha = 0.8) +
    geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
    scale_x_continuous("log10(mean gene expression)", expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    scale_fill_manual(values = c("darkgrey", "red")) +
    ggtitle("JULIA_01 - Gene Expression Distribution") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

mean_expr <- as.data.frame(mean_expr)
mean_expr_df <- data.frame(ensembl_ids = rownames(mean_expr),
                           log10_mean_expr = mean_expr[, 1])
gene_expr_distr
```

As we can see, the distribution is bimodal. The first peak corresponds to lowly expressed genes (likely to be technical artifacts), and the second represents actually expressed genes. Thus, we want our threshold to fall somewhere in the middle of the rectangular component (average count of 1):

```{r}
table(mean_expr_df$log10_mean_expr > 0)
sce <- sce[mean_expr_df$log10_mean_expr > 0, ]
```

### Identity highest expressed genes
In addition, we want to assess which is the identity of the highest expressed genes. We expect it to be housekeeping genes, such as actin beta (ACTB). However, our gene identifiers are currently Ensembl Ids, which are widely used as they are unambiguous and non-redundant, but hinder the intuitive identity of a gene. Hence, we want to convert them to gene symbols. We can interconvert them using annotation packages like `org.Hs.eg.db`.

```{r}
ensembl_ids <- str_sub(rownames(sce), 1, 15)
gene_symbols <- AnnotationDbi::select(
  org.Hs.eg.db, 
  keys = ensembl_ids, 
  keytype = "ENSEMBL", 
  columns = "SYMBOL"
)
gene_symbols <- gene_symbols[match(ensembl_ids, gene_symbols$ENSEMBL), "SYMBOL"]
index_na <- which(is.na(gene_symbols))
gene_symbols[index_na] <- rownames(sce)[index_na]
index_repeated <- which(base::duplicated(gene_symbols))
gene_symbols[index_repeated] <- str_c(
  gene_symbols[index_repeated], 
  1:(length(index_repeated)), 
  sep = "."
)
rowData(sce)$symbol <- gene_symbols
highest_expr_genes <- plotHighestExprs(sce, feature_names_to_plot = "symbol")
highest_expr_genes
```

Indeed, we see that among the highest expressed genes there are housekeeping genes such as MALAT1, ACTB, RPL and RPS genes. Of note, there are genes exclusively expressed in the immune system, such as CXCR4 or CD69.

# Batch effect and Normalization
We want to correct for two biases:

1. Library size: if cell A has twice the library size of cell B, we expect that, on average, every gene in cell A will have twice the number of counts of cell B.
2. RNA composition: we assume that most genes in cell A are not over-expressed in cell B. However, due to dropout events this might not be the case, so that the genes expressed in cells with low RNA composition (low cell coverage) will tend to be biased towards overexpression.

First, however, let us assess whether the different plates are introducing batch effects in the data:

```{r}
batch_no_norm_tsne <- plot_tsne(
  sce, 
  exprs_values = "counts",
  point_size = 2.5,
  point_alpha = 1,
  color_by = "plate", 
  colors = c("#E69F00", "#009E73", "#0072B2", "#CC79A7"),
  title = "JULIA_01 - Batch effect without normalization"
)

batch_no_norm_tsne
```

Indeed, without normalizing we see two clusters of plates: (1) P2568, P2664 and (2) P2672, P2671. Let us normalize the counts using the `scran` package to compute size factors for the count matrix and recheck the presence of batch effect:

```{r}
sce <- computeSumFactors(sce)
summary(sizeFactors(sce))
sce <- normalize(sce)
batch_norm_tsne <- plot_tsne(
  sce, 
  exprs_values = "logcounts", 
  point_size = 2.5,
  point_alpha = 1,
  color_by = "plate", 
  colors = c("#E69F00", "#009E73", "#0072B2", "#CC79A7"),
  title = "JULIA_01 - Batch effect with normalization"
)
batch_norm_tsne
```

We see that, after normalization, the batch effect disappeared.

We can see that the previous command introduced a new matrix in the "assays" layer of the `SingleCellExperiment` object, corresponding to the log-normalized expression matrix:

```{r}
assays(sce)
logcounts(sce)[1:6, 1:6]
```

Interestingly, we see that the size factors correlate almost perfectly with the library size:

```{r}
plot(sce$total_counts ~ sizeFactors(sce))
```

Thus, we are correcting mostly by differences in library size.

Finally, we will filter to retain only the highly variable genes:

# Biological analysis

## Dimensionality reduction
As we have now our expression matrix filtered and normalized, we want to proceed with the biological analyses. Let us check whether we observe the effect that time until freezing has on gene expression, which we already observed in 10X data.

We explore this idea with a tSNE, which we can do with functions from the `scater` package:

```{r}
# Remove "empty" and "NA" cells
sce <- sce[, sce$time != "empty" & !is.na(sce$time)]

# Recode "time" variable
sce$time <- factor(sce$time, time_order_all)
levels(sce$time) <- c("0h", "2h", "8h", "24h", "24h Biobank", "48h", 
                      "24h 4ºC", "48h 4ºC")
sce <- sce[, sce$time != "24h Biobank"]
rownames(sce) <- rowData(sce)$symbol

# Plot tSNE
sce <- sce %>% 
  scater::mutate(temperature = case_when(
    time %in% c("0h", "2h") ~ "0h/2h",
    time %in% c("8h", "24h", "48h") ~ "room temperature",
    time %in% c("24h 4ºC", "48h 4ºC") ~ "4ºC"
  )
)
set.seed(1)
palette <- c("#999999", "#92e8df", "#632c63", "#e4624e", "#c0e212", "#CC79A7", "#F0E442")
sce_f <- scater::filter(sce, temperature != "4ºC")
tsne_smart <- plot_tsne(
  sce = sce_f,
  exprs_value = "logcounts",
  color_by = "time",
  point_size = 1.5,
  point_alpha = 1,
  colors = palette,
  title = "Smart-seq2"
)
tsne_smart
saveRDS(tsne_smart, file = "results/R_objects/ggplots/tsne_time_points_smartseq_gg.rds")
tsne_temp <- plot_tsne(
  sce, 
  exprs_values = "logcounts", 
  color_by = "temperature", 
  point_size = 2.5, 
  point_alpha = 1,
  colors = c("#a5cded", "#999999", "#d27205"),
  title = "Smart-seq2"
)
tsne_temp <- tsne_temp +
  scale_color_manual("", values =  c("#999999", "#a5cded", "#d27205"), 
                     labels = c("0h/2h RT", "24h/48h 4ºC", "8h/24h/48h RT"))

ggarrange(plotlist = list(tsne_smart, tsne_temp), ncol = 2, nrow = 1)

# Save
ggsave(
  filename = str_c("results/plots/", date, "_tsne_smart-seq2.pdf"),
  plot = tsne_smart,
  height = 7, 
  width = 8
)
saveRDS(
  object = tsne_smart, 
  file = str_c("results/R_objects//", date, "_tsne_smart-seq2.rds")
)
```

Interestingly, we can spot the same two patterns than with 10X data:

1. The processing time seems to be a confounding factor, as the points are further away from the gold standard (0h) as time increases.
2. Transporting the samples at 4ºC seems to avoid the technical artifacts introduced by the processing time, as 24h and 48h at 4ºC seem to cluster with the ones cryopreserved immediately.

## Confounding variables
We now aim to assess which variables are introducing more variability on the dataset. We take advantage of the `plotExplanatoryVariables` function from `scater`, which fits a linear model for each gene with only one confounding factor (i.e. detected genes) as explanatory variable. Then, the distribution of R^2 values (% of explained variability) for the variables with the most explanatory power is plotted:

```{r}
explained_var <- plotExplanatoryVariables(
  sce,
  variables = c(
    "total_features_by_counts",
    "total_counts",
    "time"
  )
)
explained_var <- explained_var + 
  scale_color_discrete("", labels = c("time", "# detected genes", "library size")) +
  theme(axis.title = element_text(size = 12),
        legend.text = element_text(size = 11),
        axis.text = element_text(size = 10))

ggsave(
  filename = str_c("results/plots/", date, "_explained_variability.pdf"),
  plot = explained_var,
  height = 7, 
  width = 8
)
saveRDS(
  object = explained_var, 
  file = str_c("results/R_objects/ggplots/explained_variability_smartseq.rds")
)
explained_var     
```

We can clearly visualize that the processing time is the confounding variable that accounts for most variability.

## Clustering
We now seek to use unsupervised clustering to elucidate if cells cluster by processing time. Following the guidelines from the [Hemberg tutorial](https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html) (November 2018), as we have less than 5,000 cells, we will use the package `SC3`. This package combines different clustering solutions (obtained by k means) into a consensus matrix, and then performs hierarchical clustering of this matrix to find k clusters. 

Let us start by estimating the number of clusters:

```{r}
sce <- sc3_estimate_k(sce)
metadata(sce)$sc3$k_estimation
```

As we can see, 3 clusters were predicted. Thus, we can run `SC3` with k=2:

```{r}
set.seed(1)

# Add feature_symbol column to rowData with the gene symbols. 
# If a gene symbol is not found, use its ensembl id.
rowData(sce)$feature_symbol <- rowData(sce)$symbol

# Run SC3
sce <- sc3(sce, ks = 2, biology = TRUE)

# Plot tSNE with k = 2
tsne_k2 <- plot_tsne(
  sce = sce,
  exprs_value = "logcounts",
  color_by = "sc3_2_clusters",
  point_size = 2.5,
  point_alpha = 1,
  colors = c("royalblue1", "red2"),
  title = "SC3 clusters (k=2)"
)
tsne_k2 <- tsne_k2 +
  scale_color_manual(values = c("royalblue1", "red2"), labels = c("cluster 1", "cluster 2")) +
  theme(legend.title = element_blank())

# Save tSNE
ggsave(
  plot = tsne_k2, 
  filename = str_c("results/plots/", date, "_Smart-seq2_tsne_k2.pdf"), 
  device = "pdf",
  height = 7, 
  width = 8
)
tsne_k2
saveRDS(object = sce, file = "results/R_objects/sce_Smart-seq2.rds")
# sce <- readRDS("results/R_objects/sce_Smart-seq2.rds")

# Plot distribution of cells across clusters
cluster_distr_gg <- as.data.frame(colData(sce)) %>% 
  ggplot(aes(sc3_2_clusters, fill = temperature)) +
   geom_bar(position = "dodge") +
   geom_text(stat = 'count', aes(label =..count..), 
             position = position_dodge(width = 1), vjust = -0.25) +
   scale_x_discrete(labels = c("Cluster 1", "Cluster2")) +
   scale_y_continuous(expand = c(0,0), limits = c(0, 130)) +
   scale_fill_manual(values = c("#999999", "#a5cded", "#d27205"), 
                     labels = c("0h/2h RT", "24h/48h 4ºC", "8h/24h/48h RT")) +
   labs(x = "", y = "number of cells", fill = "") +
   theme_classic()

ggsave(
  plot = cluster_distr_gg, 
  filename = str_c("results/plots/", date, "_Smart-seq2_cluster_distr.pdf"), 
  device = "pdf",
  height = 7, 
  width = 8
)
saveRDS(tsne_k2, "results/R_objects/ggplots/tsne_Smart-seq2_clustered_k2.rds")
saveRDS(cluster_distr_gg, "results/R_objects/ggplots/barplot_cluster_distr_Smart-seq2.rds")
cluster_distr_gg
```

# Regress out 10X gene signature on Smart-seq2 data
Let us assess whether we can correct the expression profiles of the cells in the current Smart-seq2 dataset using the meta-signatures from the 10X dataset. As in this dataset we have CD3+ T cells, we will use the union of CD4+ and CD8+ meta-signatures:

```{r}
# Load 10X gene signatures 
metasignature <- readRDS(file = "results/R_objects/metasignatures.rds")
signatures_df <- readRDS(file = "results/R_objects/gene_signatures.rds")

# Join metasignatures CD4 and CD8
metasignatures_t <- metasignature[c("CD4 T", "CD8 T")]
rankings_t <- list()

for (type in c("CD4 T", "CD8 T")) {
  rankings <- map_dbl(metasignatures_t[[type]], function(g) {
    ranking <- mean(map_dbl(signatures_df[[type]], ~ which(.[!.$is_random, "gene"] == g)))
  })
  names(rankings) <- metasignatures_t[[type]]
  rankings_t[[type]] <- sort(rankings)
}
metasignature_t <- union(names(rankings_t$`CD4 T`), names(rankings_t$`CD8 T`))
signatures_df_t <- rbind(signatures_df$`CD4 T`[[1]], signatures_df$`CD8 T`[[1]])
signatures_df_t <- signatures_df_t[!signatures_df_t$is_random, ]
signatures_df_t <- signatures_df_t[match(metasignature_t, signatures_df_t$gene), ]

# Remove 17 genes not found in SCE
signatures_df_t <- signatures_df_t[metasignature_t %in% rownames(sce), ]

# Calculate time-score for every cell in SCE
sce_scored <- calc_time_score(sce = sce, signature_df = signatures_df_t)

# Visualize time-score across time points
violin_smart <- sce_scored %>% 
  colData() %>% 
  as.data.frame() %>% 
  mutate(time = factor(time, c("0h", "24h 4ºC", "48h 4ºC", "2h", "8h", "24h", "48h"))) %>% 
  mutate(label = ifelse(time %in% c("8h", "24h", "48h"), "affected", "unaffected")) %>% 
  ggplot(aes(x = time, y = time_score, fill = label)) +
    geom_violin() +
    geom_boxplot(fill = "white", width = 0.15, outlier.shape = NA) +
    scale_x_discrete("") +
    scale_y_continuous("time-score") +
    scale_fill_manual("", values = c("red2", "royalblue1")) +
    theme_bw() +
    theme(axis.text = element_text(size = 12), 
          axis.title.y = element_text(size = 14, face = "bold")) 
violin_smart
saveRDS(violin_smart, file = "results/R_objects/violin_smart.rds")

# Regress out time score
seurat_scored <- Convert(sce_scored, "seurat")
seurat_scored <- ScaleData(seurat_scored, vars.to.regress = "time_score")
assays(sce_scored)$regressed <- seurat_scored@scale.data
tsne_original <- plot_tsne(
  sce_scored, 
  exprs_values = "logcounts", 
  color_by = "sc3_2_clusters", 
  point_size = 2.5, 
  point_alpha = 1,
  colors = c("royalblue1", "red2"),
  title = "Original"
)
tsne_original <- tsne_original +
  scale_color_manual("", values = c("royalblue1", "red2"), labels = c("unaffected", "affected"))

tsne_regressed <- plot_tsne(
  sce_scored, 
  exprs_values = "regressed", 
  color_by = "sc3_2_clusters", 
  point_size = 2.5, 
  point_alpha = 1,
  colors = c("royalblue1", "red2"),
  title = "Time-Score Regressed"
)
tsne_regressed <- tsne_regressed +
  scale_color_manual("", values = c("royalblue1", "red2"), labels = c("unaffected", "affected"))
tsne_regressed
saveRDS(list(tsne_original, tsne_regressed), "results/R_objects/Smart-seq2_tsne_originalvsregressed.rds")

original_vs_regressed <- ggarrange(
  plotlist = list(tsne_original, tsne_regressed), 
  ncol = 2, 
  nrow = 1, 
  common.legend = TRUE
)

# Save
ggsave(
  filename = str_c("results/plots/", date, "_violin_time-score_Smart-seq.pdf"), 
  plot = violin_smart,
  width = 8, 
  height = 7
)

ggsave(
  filename = str_c("results/plots/", date, "_tsne_time-score_regressed_Smart-seq.pdf"), 
  plot = original_vs_regressed,
  width = 14, 
  height = 7
)
```
# Bootstrap

As in all the analysis above we used a similar proportion of “affected” and “unaffected” cells, we will  test the effect of varying percentages of time-affected cells on the time-score computation and regression. In this setting, we will perform bootstrapping as follows: first, we will sample 300 cells with replacement, enforcing an approximate percentage of time-affected cells. Second, we will compute the average silhouette width between affected and unaffected cells (as a proxy of how well the conditions separate/mix). Finally, we will correct the transcriptome profiles as described above and recalculate the average silhouette width. We will repeat this process 25 time for each of a set of percentages ranging from 10% to  90 % of affected cells.

```{r}
set.seed(1)
carry_bootstrap <- function(sce, sign_df, w_affected) {
  # Find sampling weigths
  weights <- c(1 - w_affected, w_affected)
  weights_vector <- ifelse(sce$sc3_2_clusters == 1, weights[1], weights[2])
  minor_class <- ifelse(w_affected < 0.5, 2, 1)
  
  # Sample 300 cells with replacement from cell ids
  sample_cells <- sample(
    colnames(sce), 
    size = 300, 
    replace = TRUE, 
    prob = weights_vector
  )
  sample_sce <- sce[, sample_cells]
  colnames(sample_sce) <- str_c(sample_cells, ".", as.character(1:length(sample_cells)))
  
  # Calculate % of affected cells
  pct_affected <- mean(sample_sce$sc3_2_clusters == 2) * 100
  
  # Calculate time-score
  sample_sce <- calc_time_score(sample_sce, signature_df = sign_df)
  
  # Regress out time-score
  seurat_scored <- Convert(sample_sce, "seurat")
  seurat_scored <- ScaleData(seurat_scored, vars.to.regress = "time_score")
  assays(sample_sce)$regressed <- seurat_scored@scale.data
  
  # Calculate Average Silhouette Width
  data_original <- t(logcounts(sample_sce))
  pca_data_original <- prcomp(data_original, center = TRUE) 
  dd_original <- as.matrix(dist(pca_data_original$x[, seq_len(3)]))
  sil_original <- silhouette(as.numeric(sample_sce$sc3_2_clusters), dd_original)
  batch_sil_original <- median(sil_original[sil_original[minor_class, ] == 2, 3])
  
  data_regressed <- t(assays(sample_sce)$regressed)
  pca_data_regressed <- prcomp(data_regressed, center = TRUE) 
  dd_regressed <- as.matrix(dist(pca_data_regressed$x[, seq_len(3)]))
  sil_regressed <- silhouette(as.numeric(sample_sce$sc3_2_clusters), dd_regressed)
  batch_sil_regressed <- median(sil_regressed[sil_regressed[minor_class, ] == 2, 3])
  
  # Create and return output
  output <- list(
    original = list(pct_affected = pct_affected, avg_sil_width = batch_sil_original),
    regressed = list(pct_affected = pct_affected, avg_sil_width = batch_sil_regressed)
  )
  output
}
input_df <- signatures_df_t
pcts_affected <- seq(from = 0.1, to = 0.9, by = 0.05)
boot_results_n25 <- replicate(
  n = 25, 
  expr = map(pcts_affected, ~ carry_bootstrap(sce, input_df, w_affected = .))
)
saveRDS(object = boot_results_n25, file = "results/R_objects/boot_results_n25.rds")

original_df <- boot_results_n25 %>% 
  map("original") %>% 
  map(as.data.frame) %>% 
  map(~ mutate(., is_regressed = FALSE)) %>% 
  bind_rows()
regressed_df <- boot_results_n25 %>% 
  map("regressed") %>% 
  map(as.data.frame) %>% 
  map(~ mutate(., is_regressed = TRUE)) %>% 
  bind_rows()
bootstrap_df <- bind_rows(original_df, regressed_df)

bootstrap_gg <- bootstrap_df %>% 
  ggplot(aes(pct_affected, avg_sil_width, color = is_regressed, fill = is_regressed)) +
    geom_point(size = 0.75) +
    geom_smooth(size = 1.5, alpha = 0.3, se = TRUE) +
    geom_smooth(size = 1.5, se = FALSE) +
    scale_x_continuous(limits = c(5, 95), breaks = seq(10, 100, 10)) +
    scale_y_continuous(limits = c(-0.6, 0.6)) +
    scale_color_manual(values = c("firebrick1", "olivedrab3")) +
    scale_fill_manual(values = c("firebrick3", "olivedrab4"), guide = FALSE) +
    labs(x = "Percentage affected cells (%)", y = "Median Silhouette Width",
         color = "time-score regressed") +
    theme_bw() +
    theme(axis.title = element_text(size = 19, face = "bold"))
saveRDS(bootstrap_gg, "results/R_objects/bootstrap_sil_width_pct_cells.rds")

ggsave(
  filename = str_c("results/plots/", date, "_bootstrap_sil_width.pdf"), 
  plot = bootstrap_gg, 
  width = 9, 
  height = 6.5
)
bootstrap_gg
```


# Final figure

```{r}
# Effect of time + explained variability
set.seed(1)
palette <- c("#999999", "#92e8df", "#632c63", "#e4624e", "#c0e212")
sce_f <- scater::filter(sce, temperature != "4ºC")
tsne_smart_time <- plot_tsne(
  sce = sce_f,
  exprs_value = "logcounts",
  color_by = "time",
  point_size = 3,
  point_alpha = 1,
  colors = palette,
  title = "Smart-seq2"
)
tsne_smart_time <- tsne_smart_time +
  theme(legend.position = "bottom")
legend_tsne_smart <- as_ggplot(get_legend(tsne_smart_time))
tsne_smart_time <- tsne_smart_time +
 theme(plot.title = element_blank(),
      legend.position = "none",
      plot.background = element_blank(),
      panel.border = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      axis.text = element_blank())

legend_explained_var <- as_ggplot(get_legend(explained_var))
explained_var <- explained_var +
  theme(legend.position = "none")

# SC3 clusters + distribution 0h/RT/4ºC cells in each cluster
legend_k2 <- as_ggplot(get_legend(cluster_distr_gg))
cluster_distr_gg <- cluster_distr_gg +
  theme(legend.position = "none")
tsne_k2 <- tsne_k2 +
  theme(legend.position = "bottom")
legend_tsne_k2 <- as_ggplot(get_legend(tsne_k2))
tsne_k2 <- tsne_k2 +
 theme(plot.title = element_blank(),
      legend.position = "none",
      plot.background = element_blank(),
      panel.border = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      axis.text = element_blank())

# Violin plot + tsne regressed
violin_smart <- violin_smart + 
  theme(legend.position = "none") +
  ggpubr::rotate_x_text(angle = -45, hjust = 0)
tsne_regressed <- tsne_regressed +
  theme(legend.position = "bottom") 
legend_tsne_regressed <- as_ggplot(get_legend(tsne_regressed))
tsne_regressed <- tsne_regressed +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "none",
        plot.background = element_blank(),
        panel.border = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())

# Arrange figure
tsne_smart_explained <- plot_grid(
  tsne_smart_time, 
  NULL,
  explained_var,
  ncol = 3, 
  nrow = 1,
  rel_widths = c(1, 0.1, 1),
  labels = c("a", "b"),
  align = "h",
  axis = "b"
)
k2_distr <- plot_grid(
  tsne_k2, 
  NULL,
  cluster_distr_gg,
  ncol = 3, 
  nrow = 1,
  rel_widths = c(1, 0.1, 1),
  labels = c("c", "d"),
  align = "h",
  axis = "b"
)
violin_regressed <- plot_grid(
  violin_smart, 
  NULL,
  tsne_regressed,
  ncol = 3, 
  nrow = 1,
  rel_widths = c(1, 0.1, 1),
  labels = c("e", "f"),
  align = "h",
  axis = "b"
)
smart_fig <- plot_grid(
  tsne_smart_explained, 
  NULL,
  k2_distr,
  violin_regressed,
  ncol = 1, 
  nrow = 4,
  rel_heights = c(1, 0.05, 1, 1)
)

# Save figure
ggsave(
  filename = str_c("doc/figures/R/", date, "_smart_seq_figure.pdf"), 
  plot = smart_fig, 
  width = 18, 
  height = 26,
  units = "cm"
)

# Save legends
legends_list <- list(legend_tsne_smart, legend_explained_var, legend_k2, 
                     legend_tsne_k2, legend_tsne_regressed)
names(legends_list) <- c("legend_tsne_smart", "legend_explained_var", "legend_k2", 
                         "legend_tsne_k2", "legend_tsne_regressed")
walk(names(legends_list), function(leg) {
  ggsave(
    filename = str_c("doc/figures/legends/", date, "_", leg, ".pdf"), 
    plot = legends_list[[leg]], 
    width = 9, 
    height = 5,
    units = "cm"
  )
})
```


# Session Info

```{r}
sessionInfo()
```


